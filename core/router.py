"""
ì§ˆë¬¸ ë¶„ë¥˜ ë¼ìš°í„° (Router)

ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì²˜ë¦¬ ê²½ë¡œë¡œ ë¶„ê¸°í•©ë‹ˆë‹¤.
- "document": ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸ â†’ RAG íŒŒì´í”„ë¼ì¸
- "meta":     ì‹œìŠ¤í…œ/ë¬¸ì„œ ë©”íƒ€ ì •ë³´ ì§ˆë¬¸ â†’ ì§ì ‘ ì‘ë‹µ
- "general":  ì¼ë°˜ ëŒ€í™”/ë²”ìš© ì§ˆë¬¸ â†’ LLM ì§ì ‘ ë‹µë³€
"""

import logging
from pathlib import Path

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

logger = logging.getLogger(__name__)

DATA_DIR = Path(__file__).parent.parent / "data"

# â”€â”€ ë¶„ë¥˜ìš© í”„ë¡¬í”„íŠ¸ (ê²½ëŸ‰, max_tokens=10) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CLASSIFIER_PROMPT = ChatPromptTemplate.from_messages([
    ("system", (
        "You are a question classifier. Classify the user's question into exactly one category.\n"
        "Respond with ONLY one word: document, meta, or general.\n\n"
        "Rules:\n"
        "- 'document': Questions about the CONTENT of uploaded documents "
        "(reports, data, statistics, analysis, programs, events described in documents)\n"
        "- 'meta': Questions ONLY about the technical system configuration "
        "(what documents are loaded, how many vector chunks exist, what AI model is being used). "
        "This is ONLY for system/infrastructure questions.\n"
        "- 'general': Everything else â€” greetings, general knowledge, coding questions, "
        "casual conversation, AND questions about the conversation itself "
        "(e.g. 'what did I just ask?', 'summarize our conversation', 'what was my previous question?'). "
        "Questions about the conversation or chat history are ALWAYS 'general', NEVER 'meta'."
    )),
    ("human", "{question}"),
])


def classify(question: str, llm) -> str:
    """ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ì—¬ 'document', 'meta', 'general' ì¤‘ í•˜ë‚˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    chain = CLASSIFIER_PROMPT | llm | StrOutputParser()
    try:
        result = chain.invoke({"question": question}).strip().lower()
        # ê²°ê³¼ê°€ ìœ íš¨í•œ ì¹´í…Œê³ ë¦¬ê°€ ì•„ë‹ˆë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ document ì²˜ë¦¬
        if result not in ("document", "meta", "general"):
            logger.warning(f"[ë¼ìš°í„°] ë¶„ë¥˜ ê²°ê³¼ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ: '{result}' â†’ 'document'ë¡œ í´ë°±")
            result = "document"
        logger.info(f"[ë¼ìš°í„°] '{question[:40]}...' â†’ {result}")
        return result
    except Exception as e:
        logger.error(f"[ë¼ìš°í„°] ë¶„ë¥˜ ì‹¤íŒ¨: {e} â†’ 'document'ë¡œ í´ë°±")
        return "document"


def get_meta_response(question: str, vectorstore=None) -> str:
    """ì‹œìŠ¤í…œ ë©”íƒ€ ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€í•©ë‹ˆë‹¤."""
    # ë¬¸ì„œ ëª©ë¡ ìˆ˜ì§‘ (PDF + Word)
    data_files = sorted(DATA_DIR.glob("*.pdf")) + sorted(DATA_DIR.glob("*.docx"))
    doc_list = "\n".join([f"  {i}. {f.name}" for i, f in enumerate(data_files, 1)])
    total_docs = len(data_files)

    # ë²¡í„° ìˆ˜
    vector_count = vectorstore.index.ntotal if vectorstore else "ì•Œ ìˆ˜ ì—†ìŒ"

    response = (
        f"í˜„ì¬ ì‹œìŠ¤í…œ ì •ë³´ì…ë‹ˆë‹¤.\n\n"
        f"ğŸ“„ ë¡œë“œëœ ë¬¸ì„œ ({total_docs}ê°œ):\n{doc_list}\n\n"
        f"ğŸ”¢ ë²¡í„° ì¸ë±ìŠ¤: {vector_count}ê°œ ì²­í¬\n"
    )
    return response
