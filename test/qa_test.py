"""
RAG íŒŒì´í”„ë¼ì¸ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ë„êµ¬

Slack ì—†ì´ í„°ë¯¸ë„ì—ì„œ ì§ˆë¬¸â†’ë¼ìš°íŒ…â†’ê²€ìƒ‰â†’ë‹µë³€ ì „ ê³¼ì •ì„ ìƒì„¸í•˜ê²Œ ì¶”ì í•©ë‹ˆë‹¤.

ì‹¤í–‰:
    python test/qa_test.py                          # ëŒ€í™”í˜• ëª¨ë“œ
    python test/qa_test.py "ì½”ì¹­ìŠ¤í„°ë”” 17ê¸° ìˆ˜ë£Œìœ¨ì€?"  # ë‹¨ë°œ ì§ˆë¬¸ ëª¨ë“œ
"""

import os
import sys
import json
import logging

# ìƒìœ„ í´ë”ì˜ ëª¨ë“ˆì„ import í•˜ê¸° ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from core.rag import RAG

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)


def print_separator(title: str = "", char: str = "â”€", width: int = 70):
    if title:
        padding = (width - len(title) - 2) // 2
        print(f"\n{char * padding} {title} {char * padding}")
    else:
        print(char * width)


def print_trace(trace: dict, show_prompt: bool = False):
    """RAG trace ê²°ê³¼ë¥¼ ì‚¬ëžŒì´ ì½ê¸° ì¢‹ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤."""

    # â”€â”€ ì§ˆë¬¸ + ë¼ìš°íŒ… ê²°ê³¼ â”€â”€
    print_separator("ìž…ë ¥ ì§ˆë¬¸")
    route_label = {"document": "ðŸ“„ ë¬¸ì„œ ê²€ìƒ‰", "meta": "â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´", "general": "ðŸ’¬ ì¼ë°˜ ëŒ€í™”"}
    print(f"  {trace['question']}")
    print(f"  â†’ ë¼ìš°íŒ…: {route_label.get(trace.get('route', ''), trace.get('route', '?'))}")

    # â”€â”€ ê²€ìƒ‰ ê²°ê³¼ (document ê²½ë¡œë§Œ) â”€â”€
    if trace.get("retrieved_chunks"):
        print_separator(f"ê²€ìƒ‰ëœ ì²­í¬ (Top-{len(trace['retrieved_chunks'])})")
        for i, chunk in enumerate(trace["retrieved_chunks"], 1):
            print(f"\n  [{i}] ì¶œì²˜: {chunk['source']} (p.{chunk['page']})  |  ìœ ì‚¬ë„: {chunk['score']}")
            preview = chunk["text"][:150].replace("\n", " ")
            if len(chunk["text"]) > 150:
                preview += "..."
            print(f"      {preview}")

    # â”€â”€ í”„ë¡¬í”„íŠ¸ (ì„ íƒ) â”€â”€
    if show_prompt and trace.get("prompt"):
        print_separator("LLMì— ì „ë‹¬ëœ í”„ë¡¬í”„íŠ¸ ì „ë¬¸")
        print(trace["prompt"])

    # â”€â”€ ë‹µë³€ â”€â”€
    print_separator("LLM ìƒì„± ë‹µë³€")
    print(f"  {trace['answer']}")

    # â”€â”€ ì„±ëŠ¥ ì§€í‘œ â”€â”€
    print_separator("ì„±ëŠ¥ ì§€í‘œ")
    timing = trace["timing"]
    print(f"  ë¼ìš°íŒ… ë¶„ë¥˜:      {timing.get('0_routing', '-')}ì´ˆ")
    print(f"  ë²¡í„° ê²€ìƒ‰ ì†Œìš”:   {timing.get('1_retrieval', '-')}ì´ˆ")
    print(f"  LLM ë‹µë³€ ìƒì„±:    {timing.get('2_llm_generation', '-')}ì´ˆ")
    print(f"  ì „ì²´ ì†Œìš” ì‹œê°„:   {timing.get('total', '?')}ì´ˆ")
    print(f"  ì‚¬ìš© ëª¨ë¸:        LLM={trace.get('model', '?')} / Embedding={trace.get('embedding_model', '?')}")
    print(f"  ë¼ìš°íŒ… ê²½ë¡œ:      {trace.get('route', '?')}")

    if "token_usage" in trace:
        usage = trace["token_usage"]
        print(f"  í† í° ì‚¬ìš©ëŸ‰:      í”„ë¡¬í”„íŠ¸={usage['prompt_tokens']} + ë‹µë³€={usage['completion_tokens']} = ì´ {usage['total_tokens']}í† í°")

    print_separator()


def interactive_mode(rag: RAG):
    """ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ëª¨ë“œ"""
    print("\n" + "=" * 70)
    print("  ðŸ§ª RAG íŒŒì´í”„ë¼ì¸ ë¡œì»¬ í…ŒìŠ¤íŠ¸ (ëŒ€í™”í˜• ëª¨ë“œ)")
    print("  ëª…ë ¹ì–´:")
    print("    /prompt  â€” í”„ë¡¬í”„íŠ¸ ì „ë¬¸ ì¶œë ¥ ON/OFF")
    print("    /search  â€” ê²€ìƒ‰ë§Œ ìˆ˜í–‰ (LLM í˜¸ì¶œ ì—†ì´)")
    print("    /model   â€” ëª¨ë¸ ë³€ê²½ (/model gpt-4o)")
    print("    /save    â€” ë§ˆì§€ë§‰ traceë¥¼ JSON ì €ìž¥")
    print("    /quit    â€” ì¢…ë£Œ")
    print("=" * 70)

    show_prompt = False
    last_trace = None

    while True:
        try:
            question = input("\nðŸ’¬ ì§ˆë¬¸: ").strip()
        except (KeyboardInterrupt, EOFError):
            print("\n\nðŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not question:
            continue

        if question == "/quit":
            print("ðŸ‘‹ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if question == "/prompt":
            show_prompt = not show_prompt
            status = "ON ðŸŸ¢" if show_prompt else "OFF ðŸ”´"
            print(f"  í”„ë¡¬í”„íŠ¸ ì „ë¬¸ ì¶œë ¥: {status}")
            continue

        if question == "/save":
            if last_trace:
                filepath = os.path.join(os.path.dirname(os.path.dirname(__file__)), "test/last_trace.json")
                with open(filepath, "w", encoding="utf-8") as f:
                    json.dump(last_trace, f, ensure_ascii=False, indent=2)
                print(f"  ðŸ’¾ ì €ìž¥ ì™„ë£Œ: {filepath}")
            else:
                print("  ì•„ì§ ì§ˆë¬¸í•œ ì ì´ ì—†ìŠµë‹ˆë‹¤.")
            continue

        if question.startswith("/model"):
            parts = question.split()
            if len(parts) > 1:
                try:
                    rag.set_model(parts[1])
                    print(f"  âœ… ëª¨ë¸ì´ {parts[1]}ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                except ValueError as e:
                    print(f"  âŒ {e}")
            else:
                from core.models import list_models
                print(f"  ì‚¬ìš© ê°€ëŠ¥: {', '.join(list_models())}")
            continue

        if question.startswith("/search "):
            query = question[8:].strip()
            if not query:
                print("  ì‚¬ìš©ë²•: /search ê²€ìƒ‰í•  ì§ˆë¬¸")
                continue
            print_separator(f"ê²€ìƒ‰ë§Œ ìˆ˜í–‰: '{query}'")
            results = rag.search(query)
            for i, (doc, score) in enumerate(results, 1):
                source = doc.metadata.get("source", "?")
                source_name = os.path.basename(source) if source else "?"
                page = doc.metadata.get("page", "?")
                preview = doc.page_content[:200].replace("\n", " ")
                print(f"\n  [{i}] ìœ ì‚¬ë„: {score:.4f} | ì¶œì²˜: {source_name} (p.{page})")
                print(f"      {preview}")
            print_separator()
            continue

        # â”€â”€ ì¼ë°˜ ì§ˆë¬¸ â†’ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ â”€â”€
        try:
            last_trace = rag.ask_with_trace(question, source="test")
            print_trace(last_trace, show_prompt=show_prompt)
        except Exception as e:
            print(f"\n  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()


def main():
    print("ðŸ”§ RAG ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
    rag = RAG()
    print("âœ… RAG ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\n")

    if len(sys.argv) > 1:
        question = " ".join(sys.argv[1:])
        trace = rag.ask_with_trace(question, source="test")
        print_trace(trace, show_prompt=True)
    else:
        interactive_mode(rag)


if __name__ == "__main__":
    main()
